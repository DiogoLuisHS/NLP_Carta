{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Importando Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- importando libs\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Token\n",
    "\n",
    "import pt_core_news_sm\n",
    "nlp = pt_core_news_sm.load()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(15,10)}) #-- setando tamanho dos gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Carregando Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- abrindo o dataset das cartas\n",
    "db_carta = pd.read_excel('Coleta de Dados Carta.xlsx', sheet_name='2019.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-- printando o shape do dataset\n",
    "db_carta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando % dos missing values\n",
    "round(db_carta.isnull().sum().sort_values(ascending=False) / len(db_carta), 3) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Trabalhando com o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- contanddo quantas vezes as palavras se repetem na coluna Querid\n",
    "db_carta_Querid = db_carta['Querid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando um Dataframe com a coluna Querid\n",
    "db_carta_Querid = pd.DataFrame(db_carta_Querid)\n",
    "db_carta_Querid = db_carta_Querid.reset_index()\n",
    "db_carta_Querid = db_carta_Querid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- conferindo a frequência de repetição das palavras\n",
    "db_carta_Querid['Querid'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- exportar o db_querido\n",
    "db_carta['Querid'].to_excel('Querido_2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando as palavras que mais se repetem na coluna Querid\n",
    "sns.barplot(x=db_carta_Querid['index'], y=db_carta_Querid['Querid'])\n",
    "plt.title('Palavra que mais apareceram na coluna Querid', fontsize=25)\n",
    "plt.xlabel('Palavra Preenchida', fontsize=20)\n",
    "plt.ylabel(f'Coluna {db_carta_Querid.columns[1]}', fontsize=20)\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Trabalhando com NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_carta.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando um dataset para receber as string das linhas e colunas\n",
    "db_string = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- definindo função para criação das strings\n",
    "def column_string(col):\n",
    "    \n",
    "    \"\"\" Função para transformar as colunas de um dataset\n",
    "    em uma única string\"\"\"\n",
    "    \n",
    "    for i in range(2, col.shape[1]):\n",
    "        db_teste = pd.DataFrame()\n",
    "        db_teste['teste'] = re.findall(r'\\w+', str(col.iloc[:, i]))\n",
    "        db_string[col.columns[i]] = db_teste['teste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando a função column_string\n",
    "column_string(db_carta)\n",
    "db_string.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Existem muitas palavras que não são interessantes de contar, por isso, irei aplicar um algoritmo para removê-las"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Verificando os stop_word da biblioteca spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dezasseis', 'menor', 'muito', 'pois', 'algo', 'disso', 'demais', 'novas', 'vêm', 'dão', 'qualquer', 'nos', 'mesmo', 'próxima', 'fazes', 'mas', 'lá', 'outros', 'porque', 'na', 'possivelmente', 'pela', 'apontar', 'obrigada', 'nem', 'sei', 'foste', 'segunda', 'ou', 'dizem', 'talvez', 'põe', 'fazem', 'portanto', 'por', 'todas', 'pelas', 'sua', 'nove', 'ademais', 'como', 'adeus', 'agora', 'poder', 'estava', 'das', 'fomos', 'estará', 'onze', 'teve', 'terceira', 'você', 'põem', 'perto', 'sob', 'foi', 'comprida', 'três', 'sois', 'os', 'ambos', 'diante', 'aquela', 'doze', 'eles', 'nesta', 'meio', 'estado', 'quanto', 'vos', 'cinco', 'numa', 'depois', 'enquanto', 'parte', 'ir', 'comprido', 'parece', 'têm', 'contra', 'faço', 'cima', 'vossas', 'esses', 'muitos', 'às', 'maior', 'minhas', 'esta', 'segundo', 'tal', 'mais', 'estas', 'terceiro', 'aos', 'só', 'quer', 'fazemos', 'estes', 'bastante', 'tiveste', 'vindo', 'quem', 'meses', 'área', 'após', 'vais', 'vens', 'cuja', 'pôde', 'nuns', 'obrigado', 'apoia', 'aquelas', 'custa', 'último', 'bem', 'através', 'final', 'próprio', 'sem', 'naquele', 'vosso', 'pode', 'todo', 'breve', 'ver', 'ao', 'sete', 'lado', 'fazia', 'porém', 'seu', 'des', 'lugar', 'da', 'inclusive', 'nas', 'vez', 'ponto', 'seis', 'quinze', 'outra', 'tais', 'eventual', 'pontos', 'diz', 'quais', 'dois', 'seus', 'irá', 'não', 'cada', 'certamente', 'algumas', 'dá', 'nunca', 'seria', 'máximo', 'dentro', 'sou', 'vinda', 'grandes', 'deste', 'tudo', 'podem', 'boa', 'vem', 'tanta', 'possível', 'vossa', 'dezassete', 'sempre', 'cedo', 'aquele', 'longe', 'vezes', 'aquilo', 'no', 'quieto', 'caminho', 'me', 'estão', 'ser', 'desse', 'meu', 'minha', 'sabe', 'todos', 'desde', 'tendes', 'oitava', 'maiorias', 'grupo', 'ambas', 'quinto', 'uns', 'tuas', 'forma', 'quieta', 'vários', 'além', 'ela', 'for', 'conhecido', 'valor', 'fazer', 'teu', 'toda', 'novo', 'assim', 'nível', 'pouco', 'fez', 'que', 'devem', 'quê', 'tentei', 'menos', 'és', 'nenhuma', 'tivemos', 'partir', 'nada', 'eu', 'cento', 'vossos', 'sexto', 'quinta', 'com', 'querem', 'favor', 'isto', 'também', 'já', 'tenho', 'logo', 'tão', 'até', 'são', 'maioria', 'dos', 'pouca', 'nessa', 'do', 'apenas', 'geral', 'nossos', 'cujo', 'veja', 'suas', 'umas', 'onde', 'dezanove', 'nesse', 'vós', 'acerca', 'estar', 'usa', 'tiveram', 'nova', 'oito', 'tive', 'contudo', 'fazeis', 'ele', 'era', 'cá', 'nós', 'puderam', 'porquanto', 'tua', 'deve', 'usar', 'fará', 'grande', 'somente', 'tarde', 'teus', 'ainda', 'falta', 'porquê', 'neste', 'uma', 'ligado', 'se', 'inicio', 'oitavo', 'tivestes', 'outras', 'sim', 'ontem', 'nosso', 'daquele', 'dezoito', 'nossa', 'quatro', 'debaixo', 'primeiro', 'lhe', 'tens', 'conhecida', 'posição', 'quarta', 'qual', 'questão', 'baixo', 'essa', 'saber', 'faz', 'mil', 'este', 'tentar', 'entre', 'números', 'iniciar', 'sétima', 'dizer', 'local', 'antes', 'estou', 'vinte', 'tipo', 'isso', 'corrente', 'pelo', 'ali', 'te', 'em', 'dessa', 'esteve', 'novos', 'quero', 'então', 'deverá', 'essas', 'ora', 'tu', 'estás', 'relação', 'para', 'pegar', 'exemplo', 'meus', 'sexta', 'apoio', 'certeza', 'mal', 'tem', 'à', 'fostes', 'vão', 'podia', 'estiveram', 'estivestes', 'sétimo', 'treze', 'naquela', 'tanto', 'sistema', 'tempo', 'quarto', 'pelos', 'estive', 'catorze', 'estiveste', 'esse', 'fui', 'coisa', 'posso', 'alguns', 'dez', 'tente', 'embora', 'somos', 'está', 'fim', 'tentaram', 'próximo', 'povo', 'aqueles', 'aí', 'de', 'é', 'sobre', 'bom', 'duas', 'atrás', 'daquela', 'momento', 'vai', 'quando', 'aqui', 'número', 'temos', 'dar', 'primeira', 'as', 'mês', 'um', 'vocês', 'foram', 'elas', 'nossas', 'poderá', 'num', 'conselho', 'fora', 'direita', 'zero', 'desta', 'estivemos', 'ter'}\n"
     ]
    }
   ],
   "source": [
    "#-- verificando as stop_word da biblioteca spacy\n",
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando um objetico com as stop_words em português\n",
    "stop_words_getter = lambda token: token.is_stop or token.lower_ in STOP_WORDS or token.lemma_ in STOP_WORDS\n",
    "Token.set_extension('is_stop', getter=stop_words_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando\n",
    "for word in STOP_WORDS:\n",
    "    lexeme = nlp.vocab[word]\n",
    "    lexeme.is_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Agora vou printar as palavaras presentes na coluna e identificar se são ou não uma **stopword**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando um DataFrame\n",
    "my_doc = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- definindo função para criação das strings\n",
    "def func_nlp(col2):\n",
    "    \n",
    "    \"\"\" Função para transformar as colunas de um dataset\n",
    "    em uma única string\"\"\"\n",
    "    \n",
    "    for i in range(2, col2.shape[1]):\n",
    "        db_teste = pd.DataFrame()\n",
    "        db_teste['teste'] = nlp(str(col2.iloc[:, i]))\n",
    "        my_doc[col2.columns[i]] = db_teste['teste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando a função func_nlp\n",
    "func_nlp(db_carta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando o head\n",
    "my_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-- printando as palavras para verificar se são ou não stop_words\n",
    "for i in range(0, my_doc.shape[1]):\n",
    "    for token in my_doc.iloc[:,i]:\n",
    "        print(token, token.lemma_, token._.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando um dataframe\n",
    "db_lemmas = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando lista\n",
    "d={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- checando os valores\n",
    "str(db_carta.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando a remoção das stop_words\n",
    "def lemmas_remov(db_lemma):\n",
    "    for i in range(2, db_carta.shape[1]):\n",
    "        lemmas = [token.lemma_ for token in nlp(str(db_carta.iloc[:,i].values)) if not token.is_stop]\n",
    "        lemmas = [lemma for lemma in lemmas if len(lemma)>2]\n",
    "        lemmas = [lemma for lemma in lemmas if '...' not in lemma]\n",
    "        lemmas = [lemma for lemma in lemmas if ' ' not in lemma]\n",
    "        #db_lemmas[db_lemma.columns[i]] = lemmas\n",
    "        d[\"string{0}\".format(i)] = pd.DataFrame(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando o head do dataset\n",
    "my_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- aplicando a função lemmas_remov\n",
    "lemmas_remov(my_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d['string10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.DataFrame(d['string10'])\n",
    "wordcount = Counter(teste[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_export = pd.DataFrame(list(wordcount))\n",
    "db_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste.to_excel(str(db_carta.columns[10])+'_2019.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- printando as primeiras 30 palavras que mais se repetem\n",
    "wordcount.most_common(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos com as palavras mais citadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- criando um DataFrame com o resultado da contagem\n",
    "df = pd.DataFrame.from_dict(wordcount, orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- ordenando o dataset pela string que mais parece\n",
    "df = df.sort_values(by=0, ascending=False)\n",
    "df = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- plotando as palavras que mais se repetem na coluna Estou\n",
    "sns.barplot(x=df['index'], y=df[0])\n",
    "plt.xlabel('Palavras mais utilizadas', fontsize=20)\n",
    "plt.ylabel('Frequência das palavras', fontsize=20)\n",
    "plt.rc('xtick', labelsize=20)\n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.title('Palavras mais utilizadas X Frequência das palavras', fontsize=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
